2024-11-24 19:40:55,979 - INFO - 
==================================================
2024-11-24 19:40:55,980 - INFO - Data Analysis:
2024-11-24 19:40:55,980 - INFO - Training set shape: (11576, 197)
2024-11-24 19:40:55,980 - INFO - Test set shape: (2000, 197)
2024-11-24 19:40:55,980 - INFO - 
Target distribution:
2024-11-24 19:40:55,980 - INFO - Mean: 16829.09
2024-11-24 19:40:55,980 - INFO - Std: 9786.48
2024-11-24 19:40:55,980 - INFO - Min: 795.00
2024-11-24 19:40:55,980 - INFO - Max: 126000.00
2024-11-24 19:40:55,980 - INFO - ==================================================

2024-11-24 19:40:55,993 - INFO - Starting K-Fold Cross Validation
2024-11-24 19:40:55,993 - INFO - Configuration: {'learning_rate': 0.002, 'weight_decay': 0.001, 'batch_size': 64, 'epochs': 120, 'random_state': 42, 'patience': 15, 'lr_scheduler': {'factor': 0.5, 'patience': 15, 'min_lr': 0.0001}}
2024-11-24 19:40:55,994 - INFO - 
Fold 1/5
2024-11-24 19:40:55,994 - INFO - Train size: 9260, Validation size: 2316
2024-11-24 19:41:06,465 - INFO - Epoch 20/120:
2024-11-24 19:41:06,465 - INFO -   Training Loss: 201453420.3034
2024-11-24 19:41:06,465 - INFO -   Validation RMSE: 13236.0068
2024-11-24 19:41:06,465 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:41:16,909 - INFO - Epoch 40/120:
2024-11-24 19:41:16,909 - INFO -   Training Loss: 33091834.9517
2024-11-24 19:41:16,909 - INFO -   Validation RMSE: 5319.3984
2024-11-24 19:41:16,909 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:41:28,061 - INFO - Epoch 60/120:
2024-11-24 19:41:28,061 - INFO -   Training Loss: 12970864.8552
2024-11-24 19:41:28,061 - INFO -   Validation RMSE: 2882.4209
2024-11-24 19:41:28,061 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:41:39,269 - INFO - Epoch 80/120:
2024-11-24 19:41:39,270 - INFO -   Training Loss: 8833663.9190
2024-11-24 19:41:39,270 - INFO -   Validation RMSE: 2316.8560
2024-11-24 19:41:39,270 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:41:50,443 - INFO - Epoch 100/120:
2024-11-24 19:41:50,443 - INFO -   Training Loss: 7789627.3319
2024-11-24 19:41:50,443 - INFO -   Validation RMSE: 2265.4998
2024-11-24 19:41:50,443 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:41:57,203 - INFO - Early stopping triggered at epoch 112
2024-11-24 19:41:57,207 - INFO - Fold 1 best RMSE: 2123.3105
2024-11-24 19:41:57,208 - INFO - 
Fold 2/5
2024-11-24 19:41:57,208 - INFO - Train size: 9261, Validation size: 2315
2024-11-24 19:42:08,433 - INFO - Epoch 20/120:
2024-11-24 19:42:08,433 - INFO -   Training Loss: 196931831.5586
2024-11-24 19:42:08,433 - INFO -   Validation RMSE: 14173.3066
2024-11-24 19:42:08,433 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:42:19,623 - INFO - Epoch 40/120:
2024-11-24 19:42:19,624 - INFO -   Training Loss: 31622504.6207
2024-11-24 19:42:19,625 - INFO -   Validation RMSE: 5817.1694
2024-11-24 19:42:19,625 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:42:30,861 - INFO - Epoch 60/120:
2024-11-24 19:42:30,861 - INFO -   Training Loss: 12236829.0724
2024-11-24 19:42:30,861 - INFO -   Validation RMSE: 3298.8286
2024-11-24 19:42:30,861 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:42:42,170 - INFO - Epoch 80/120:
2024-11-24 19:42:42,171 - INFO -   Training Loss: 8683571.4086
2024-11-24 19:42:42,171 - INFO -   Validation RMSE: 2608.6040
2024-11-24 19:42:42,171 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:42:53,436 - INFO - Epoch 100/120:
2024-11-24 19:42:53,436 - INFO -   Training Loss: 7902918.9207
2024-11-24 19:42:53,436 - INFO -   Validation RMSE: 2688.1628
2024-11-24 19:42:53,436 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:42:54,568 - INFO - Early stopping triggered at epoch 102
2024-11-24 19:42:54,571 - INFO - Fold 2 best RMSE: 2568.6130
2024-11-24 19:42:54,571 - INFO - 
Fold 3/5
2024-11-24 19:42:54,571 - INFO - Train size: 9261, Validation size: 2315
2024-11-24 19:43:05,854 - INFO - Epoch 20/120:
2024-11-24 19:43:05,856 - INFO -   Training Loss: 196866233.6000
2024-11-24 19:43:05,856 - INFO -   Validation RMSE: 13981.6484
2024-11-24 19:43:05,856 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:43:17,167 - INFO - Epoch 40/120:
2024-11-24 19:43:17,167 - INFO -   Training Loss: 31219886.1517
2024-11-24 19:43:17,167 - INFO -   Validation RMSE: 5965.0088
2024-11-24 19:43:17,167 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:43:28,532 - INFO - Epoch 60/120:
2024-11-24 19:43:28,533 - INFO -   Training Loss: 11788402.3397
2024-11-24 19:43:28,533 - INFO -   Validation RMSE: 3542.9021
2024-11-24 19:43:28,533 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:43:39,846 - INFO - Epoch 80/120:
2024-11-24 19:43:39,846 - INFO -   Training Loss: 7230432.1655
2024-11-24 19:43:39,846 - INFO -   Validation RMSE: 3197.7234
2024-11-24 19:43:39,846 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:43:51,250 - INFO - Epoch 100/120:
2024-11-24 19:43:51,251 - INFO -   Training Loss: 7242573.0422
2024-11-24 19:43:51,251 - INFO -   Validation RMSE: 3229.6555
2024-11-24 19:43:51,251 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:44:01,597 - INFO - Early stopping triggered at epoch 118
2024-11-24 19:44:01,600 - INFO - Fold 3 best RMSE: 3135.1335
2024-11-24 19:44:01,600 - INFO - 
Fold 4/5
2024-11-24 19:44:01,600 - INFO - Train size: 9261, Validation size: 2315
2024-11-24 19:44:12,874 - INFO - Epoch 20/120:
2024-11-24 19:44:12,876 - INFO -   Training Loss: 199319910.1793
2024-11-24 19:44:12,876 - INFO -   Validation RMSE: 14109.6836
2024-11-24 19:44:12,876 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:44:24,254 - INFO - Epoch 40/120:
2024-11-24 19:44:24,255 - INFO -   Training Loss: 32833149.9862
2024-11-24 19:44:24,255 - INFO -   Validation RMSE: 5815.9507
2024-11-24 19:44:24,255 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:44:35,177 - INFO - Epoch 60/120:
2024-11-24 19:44:35,177 - INFO -   Training Loss: 13546646.6586
2024-11-24 19:44:35,178 - INFO -   Validation RMSE: 3113.4500
2024-11-24 19:44:35,178 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:44:46,136 - INFO - Epoch 80/120:
2024-11-24 19:44:46,136 - INFO -   Training Loss: 8937512.5741
2024-11-24 19:44:46,136 - INFO -   Validation RMSE: 2344.9485
2024-11-24 19:44:46,136 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:44:53,808 - INFO - Early stopping triggered at epoch 94
2024-11-24 19:44:53,812 - INFO - Fold 4 best RMSE: 2214.6997
2024-11-24 19:44:53,812 - INFO - 
Fold 5/5
2024-11-24 19:44:53,812 - INFO - Train size: 9261, Validation size: 2315
2024-11-24 19:45:05,110 - INFO - Epoch 20/120:
2024-11-24 19:45:05,110 - INFO -   Training Loss: 199744392.8828
2024-11-24 19:45:05,110 - INFO -   Validation RMSE: 13737.7471
2024-11-24 19:45:05,110 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:45:16,533 - INFO - Epoch 40/120:
2024-11-24 19:45:16,533 - INFO -   Training Loss: 32775971.6759
2024-11-24 19:45:16,533 - INFO -   Validation RMSE: 5079.2363
2024-11-24 19:45:16,533 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:45:27,915 - INFO - Epoch 60/120:
2024-11-24 19:45:27,916 - INFO -   Training Loss: 13275513.2241
2024-11-24 19:45:27,916 - INFO -   Validation RMSE: 2880.3813
2024-11-24 19:45:27,916 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:45:39,323 - INFO - Epoch 80/120:
2024-11-24 19:45:39,324 - INFO -   Training Loss: 8095599.6810
2024-11-24 19:45:39,324 - INFO -   Validation RMSE: 2195.8457
2024-11-24 19:45:39,324 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:45:50,767 - INFO - Epoch 100/120:
2024-11-24 19:45:50,767 - INFO -   Training Loss: 7504186.8086
2024-11-24 19:45:50,767 - INFO -   Validation RMSE: 2134.0889
2024-11-24 19:45:50,767 - INFO -   Current Learning Rate: 0.002000
2024-11-24 19:45:55,325 - INFO - Early stopping triggered at epoch 108
2024-11-24 19:45:55,329 - INFO - Fold 5 best RMSE: 2091.1592
2024-11-24 19:45:55,330 - INFO - 
Cross-Validation Results:
2024-11-24 19:45:55,330 - INFO - Mean RMSE: 2426.5835
2024-11-24 19:45:55,330 - INFO - Std RMSE: 392.8344
2024-11-24 19:45:55,330 - INFO - 
Training Final Model
2024-11-24 19:46:02,173 - INFO - Epoch 10/120:
2024-11-24 19:46:02,173 - INFO -   Training Loss: 8200160.1892
2024-11-24 19:46:02,174 - INFO -   Learning Rate: 0.002000
2024-11-24 19:46:09,056 - INFO - Epoch 20/120:
2024-11-24 19:46:09,057 - INFO -   Training Loss: 7856160.1506
2024-11-24 19:46:09,057 - INFO -   Learning Rate: 0.002000
2024-11-24 19:46:15,912 - INFO - Epoch 30/120:
2024-11-24 19:46:15,912 - INFO -   Training Loss: 7227577.5414
2024-11-24 19:46:15,912 - INFO -   Learning Rate: 0.001000
2024-11-24 19:46:22,737 - INFO - Epoch 40/120:
2024-11-24 19:46:22,737 - INFO -   Training Loss: 7294877.2790
2024-11-24 19:46:22,737 - INFO -   Learning Rate: 0.000500
2024-11-24 19:46:29,569 - INFO - Epoch 50/120:
2024-11-24 19:46:29,569 - INFO -   Training Loss: 7365992.1519
2024-11-24 19:46:29,569 - INFO -   Learning Rate: 0.000250
2024-11-24 19:46:36,447 - INFO - Epoch 60/120:
2024-11-24 19:46:36,447 - INFO -   Training Loss: 7124570.5297
2024-11-24 19:46:36,447 - INFO -   Learning Rate: 0.000125
2024-11-24 19:46:43,348 - INFO - Epoch 70/120:
2024-11-24 19:46:43,349 - INFO -   Training Loss: 6754631.6215
2024-11-24 19:46:43,349 - INFO -   Learning Rate: 0.000031
2024-11-24 19:46:50,206 - INFO - Epoch 80/120:
2024-11-24 19:46:50,207 - INFO -   Training Loss: 6402796.3660
2024-11-24 19:46:50,207 - INFO -   Learning Rate: 0.000016
2024-11-24 19:46:57,007 - INFO - Epoch 90/120:
2024-11-24 19:46:57,007 - INFO -   Training Loss: 6940809.1084
2024-11-24 19:46:57,007 - INFO -   Learning Rate: 0.000008
2024-11-24 19:47:00,467 - INFO - Early stopping triggered at epoch 95
2024-11-24 19:47:00,473 - INFO - 
Training completed. Best model saved.
