2024-11-24 11:02:41,772 - INFO - 
==================================================
2024-11-24 11:02:41,772 - INFO - Data Analysis:
2024-11-24 11:02:41,772 - INFO - Training set shape: (10000, 197)
2024-11-24 11:02:41,772 - INFO - Test set shape: (2000, 197)
2024-11-24 11:02:41,772 - INFO - 
Target distribution:
2024-11-24 11:02:41,772 - INFO - Mean: 16849.08
2024-11-24 11:02:41,772 - INFO - Std: 9846.69
2024-11-24 11:02:41,772 - INFO - Min: 795.00
2024-11-24 11:02:41,772 - INFO - Max: 126000.00
2024-11-24 11:02:41,772 - INFO - ==================================================

2024-11-24 11:02:41,785 - INFO - Starting K-Fold Cross Validation
2024-11-24 11:02:41,785 - INFO - Configuration: {'learning_rate': 0.003, 'weight_decay': 0.001, 'batch_size': 64, 'epochs': 120, 'random_state': 42, 'patience': 20, 'lr_scheduler': {'factor': 0.5, 'patience': 5, 'min_lr': 1e-06}}
2024-11-24 11:02:41,787 - INFO - 
Fold 1/5
2024-11-24 11:02:41,787 - INFO - Train size: 8000, Validation size: 2000
2024-11-24 11:02:52,293 - INFO - Epoch 20/120:
2024-11-24 11:02:52,294 - INFO -   Training Loss: 124724020.7040
2024-11-24 11:02:52,294 - INFO -   Validation RMSE: 10866.1895
2024-11-24 11:02:52,294 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:03:01,993 - INFO - Epoch 40/120:
2024-11-24 11:03:01,994 - INFO -   Training Loss: 15767045.4840
2024-11-24 11:03:01,994 - INFO -   Validation RMSE: 3182.5103
2024-11-24 11:03:01,994 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:03:12,059 - INFO - Epoch 60/120:
2024-11-24 11:03:12,059 - INFO -   Training Loss: 13168765.7240
2024-11-24 11:03:12,059 - INFO -   Validation RMSE: 2635.4492
2024-11-24 11:03:12,059 - INFO -   Current Learning Rate: 0.001500
2024-11-24 11:03:21,578 - INFO - Epoch 80/120:
2024-11-24 11:03:21,578 - INFO -   Training Loss: 9476208.6120
2024-11-24 11:03:21,578 - INFO -   Validation RMSE: 2434.4019
2024-11-24 11:03:21,578 - INFO -   Current Learning Rate: 0.000750
2024-11-24 11:03:31,149 - INFO - Epoch 100/120:
2024-11-24 11:03:31,149 - INFO -   Training Loss: 8852491.0840
2024-11-24 11:03:31,150 - INFO -   Validation RMSE: 2473.4409
2024-11-24 11:03:31,150 - INFO -   Current Learning Rate: 0.000188
2024-11-24 11:03:32,600 - INFO - Early stopping triggered at epoch 103
2024-11-24 11:03:32,603 - INFO - Fold 1 best RMSE: 2246.9783
2024-11-24 11:03:32,604 - INFO - 
Fold 2/5
2024-11-24 11:03:32,604 - INFO - Train size: 8000, Validation size: 2000
2024-11-24 11:03:42,199 - INFO - Epoch 20/120:
2024-11-24 11:03:42,200 - INFO -   Training Loss: 121882476.7360
2024-11-24 11:03:42,200 - INFO -   Validation RMSE: 10955.3828
2024-11-24 11:03:42,200 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:03:51,780 - INFO - Epoch 40/120:
2024-11-24 11:03:51,781 - INFO -   Training Loss: 15581026.5400
2024-11-24 11:03:51,781 - INFO -   Validation RMSE: 3547.5295
2024-11-24 11:03:51,781 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:04:01,461 - INFO - Epoch 60/120:
2024-11-24 11:04:01,461 - INFO -   Training Loss: 10977472.5660
2024-11-24 11:04:01,461 - INFO -   Validation RMSE: 2816.4797
2024-11-24 11:04:01,461 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:04:11,014 - INFO - Epoch 80/120:
2024-11-24 11:04:11,014 - INFO -   Training Loss: 7719824.4800
2024-11-24 11:04:11,014 - INFO -   Validation RMSE: 2929.4724
2024-11-24 11:04:11,014 - INFO -   Current Learning Rate: 0.000375
2024-11-24 11:04:11,014 - INFO - Early stopping triggered at epoch 80
2024-11-24 11:04:11,018 - INFO - Fold 2 best RMSE: 2816.4797
2024-11-24 11:04:11,018 - INFO - 
Fold 3/5
2024-11-24 11:04:11,018 - INFO - Train size: 8000, Validation size: 2000
2024-11-24 11:04:20,682 - INFO - Epoch 20/120:
2024-11-24 11:04:20,682 - INFO -   Training Loss: 120580864.5120
2024-11-24 11:04:20,682 - INFO -   Validation RMSE: 11121.8164
2024-11-24 11:04:20,682 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:04:30,282 - INFO - Epoch 40/120:
2024-11-24 11:04:30,282 - INFO -   Training Loss: 13888147.0680
2024-11-24 11:04:30,282 - INFO -   Validation RMSE: 3912.2415
2024-11-24 11:04:30,282 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:04:39,825 - INFO - Epoch 60/120:
2024-11-24 11:04:39,825 - INFO -   Training Loss: 9985795.3000
2024-11-24 11:04:39,826 - INFO -   Validation RMSE: 3586.1479
2024-11-24 11:04:39,826 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:04:49,423 - INFO - Epoch 80/120:
2024-11-24 11:04:49,423 - INFO -   Training Loss: 7281276.6500
2024-11-24 11:04:49,423 - INFO -   Validation RMSE: 3450.0103
2024-11-24 11:04:49,423 - INFO -   Current Learning Rate: 0.001500
2024-11-24 11:04:59,025 - INFO - Epoch 100/120:
2024-11-24 11:04:59,025 - INFO -   Training Loss: 7276199.6120
2024-11-24 11:04:59,025 - INFO -   Validation RMSE: 3438.4026
2024-11-24 11:04:59,025 - INFO -   Current Learning Rate: 0.000188
2024-11-24 11:05:08,629 - INFO - Epoch 120/120:
2024-11-24 11:05:08,629 - INFO -   Training Loss: 7383494.9930
2024-11-24 11:05:08,629 - INFO -   Validation RMSE: 3594.8352
2024-11-24 11:05:08,629 - INFO -   Current Learning Rate: 0.000023
2024-11-24 11:05:08,632 - INFO - Fold 3 best RMSE: 3408.8354
2024-11-24 11:05:08,632 - INFO - 
Fold 4/5
2024-11-24 11:05:08,632 - INFO - Train size: 8000, Validation size: 2000
2024-11-24 11:05:18,253 - INFO - Epoch 20/120:
2024-11-24 11:05:18,254 - INFO -   Training Loss: 122543392.1280
2024-11-24 11:05:18,254 - INFO -   Validation RMSE: 11068.4990
2024-11-24 11:05:18,254 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:05:27,960 - INFO - Epoch 40/120:
2024-11-24 11:05:27,960 - INFO -   Training Loss: 15678571.6760
2024-11-24 11:05:27,960 - INFO -   Validation RMSE: 3297.4309
2024-11-24 11:05:27,960 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:05:37,658 - INFO - Epoch 60/120:
2024-11-24 11:05:37,659 - INFO -   Training Loss: 11747513.3300
2024-11-24 11:05:37,659 - INFO -   Validation RMSE: 2667.8601
2024-11-24 11:05:37,659 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:05:47,350 - INFO - Epoch 80/120:
2024-11-24 11:05:47,350 - INFO -   Training Loss: 8566462.4580
2024-11-24 11:05:47,350 - INFO -   Validation RMSE: 2363.5076
2024-11-24 11:05:47,350 - INFO -   Current Learning Rate: 0.001500
2024-11-24 11:05:55,582 - INFO - Early stopping triggered at epoch 97
2024-11-24 11:05:55,585 - INFO - Fold 4 best RMSE: 2242.3850
2024-11-24 11:05:55,586 - INFO - 
Fold 5/5
2024-11-24 11:05:55,586 - INFO - Train size: 8000, Validation size: 2000
2024-11-24 11:06:05,285 - INFO - Epoch 20/120:
2024-11-24 11:06:05,286 - INFO -   Training Loss: 122865457.4720
2024-11-24 11:06:05,286 - INFO -   Validation RMSE: 10706.1758
2024-11-24 11:06:05,286 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:06:15,005 - INFO - Epoch 40/120:
2024-11-24 11:06:15,005 - INFO -   Training Loss: 16375877.4720
2024-11-24 11:06:15,005 - INFO -   Validation RMSE: 3141.9231
2024-11-24 11:06:15,005 - INFO -   Current Learning Rate: 0.003000
2024-11-24 11:06:24,717 - INFO - Epoch 60/120:
2024-11-24 11:06:24,717 - INFO -   Training Loss: 12210091.2560
2024-11-24 11:06:24,717 - INFO -   Validation RMSE: 3096.9814
2024-11-24 11:06:24,717 - INFO -   Current Learning Rate: 0.001500
2024-11-24 11:06:34,367 - INFO - Epoch 80/120:
2024-11-24 11:06:34,368 - INFO -   Training Loss: 10761480.2400
2024-11-24 11:06:34,368 - INFO -   Validation RMSE: 2479.4175
2024-11-24 11:06:34,368 - INFO -   Current Learning Rate: 0.000375
2024-11-24 11:06:44,094 - INFO - Epoch 100/120:
2024-11-24 11:06:44,094 - INFO -   Training Loss: 9995336.5460
2024-11-24 11:06:44,094 - INFO -   Validation RMSE: 2340.1851
2024-11-24 11:06:44,094 - INFO -   Current Learning Rate: 0.000094
2024-11-24 11:06:53,785 - INFO - Epoch 120/120:
2024-11-24 11:06:53,786 - INFO -   Training Loss: 10177838.3340
2024-11-24 11:06:53,786 - INFO -   Validation RMSE: 2379.8306
2024-11-24 11:06:53,786 - INFO -   Current Learning Rate: 0.000047
2024-11-24 11:06:53,789 - INFO - Fold 5 best RMSE: 2325.9299
2024-11-24 11:06:53,789 - INFO - 
Cross-Validation Results:
2024-11-24 11:06:53,789 - INFO - Mean RMSE: 2608.1216
2024-11-24 11:06:53,789 - INFO - Std RMSE: 453.5142
2024-11-24 11:06:53,789 - INFO - 
Training Final Model
2024-11-24 11:06:59,796 - INFO - Epoch 10/120:
2024-11-24 11:06:59,796 - INFO -   Training Loss: 8961845.6975
2024-11-24 11:06:59,796 - INFO -   Learning Rate: 0.003000
2024-11-24 11:07:05,824 - INFO - Epoch 20/120:
2024-11-24 11:07:05,825 - INFO -   Training Loss: 8445605.1210
2024-11-24 11:07:05,825 - INFO -   Learning Rate: 0.001500
2024-11-24 11:07:11,699 - INFO - Epoch 30/120:
2024-11-24 11:07:11,699 - INFO -   Training Loss: 7635151.0924
2024-11-24 11:07:11,699 - INFO -   Learning Rate: 0.000750
2024-11-24 11:07:17,702 - INFO - Epoch 40/120:
2024-11-24 11:07:17,703 - INFO -   Training Loss: 7925216.4825
2024-11-24 11:07:17,703 - INFO -   Learning Rate: 0.000375
2024-11-24 11:07:23,399 - INFO - Epoch 50/120:
2024-11-24 11:07:23,400 - INFO -   Training Loss: 7935435.2850
2024-11-24 11:07:23,400 - INFO -   Learning Rate: 0.000188
2024-11-24 11:07:28,940 - INFO - Epoch 60/120:
2024-11-24 11:07:28,940 - INFO -   Training Loss: 7523488.8161
2024-11-24 11:07:28,940 - INFO -   Learning Rate: 0.000094
2024-11-24 11:07:34,461 - INFO - Epoch 70/120:
2024-11-24 11:07:34,462 - INFO -   Training Loss: 7921148.1290
2024-11-24 11:07:34,462 - INFO -   Learning Rate: 0.000023
2024-11-24 11:07:37,235 - INFO - Early stopping triggered at epoch 75
2024-11-24 11:07:37,252 - INFO - 
Training completed. Best model and predictions saved.
